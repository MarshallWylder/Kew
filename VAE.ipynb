{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def read_file(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            mass, intensity = line.strip().split('\\t')\n",
    "            data.append([float(mass), float(intensity)])\n",
    "    return np.array(data)\n",
    "\n",
    "directory = r'C:\\Users\\Marshall\\TEST DATA\\TEST DATA\\DalbergiaLatifolia'\n",
    "file_paths = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.txt')]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "all_data = []\n",
    "for file_path in file_paths:\n",
    "    data = pd.read_csv(file_path,sep= '\\t',header = 1)\n",
    "    all_data.append(data)\n",
    "\n",
    "all_data = np.concatenate(all_data, axis=0)\n",
    "\n",
    "# Normalize the data\n",
    "means = np.mean(all_data, axis=0)\n",
    "stds = np.std(all_data, axis=0)\n",
    "normalized_data = (all_data - means) / stds\n",
    "\n",
    "data_tensor = torch.from_numpy(normalized_data).float()\n",
    "data_tensor = data_tensor.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAE setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the VAE model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.mu = nn.Linear(256, latent_dim)\n",
    "        self.log_var = nn.Linear(256, latent_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, input_dim),\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu = self.mu(h)\n",
    "        log_var = self.log_var(h)\n",
    "        return mu, log_var\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        return z\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_recon = self.decode(z)\n",
    "        return x_recon, mu, log_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 102.6587\n",
      "Epoch [2/100], Loss: 102.8241\n",
      "Epoch [3/100], Loss: 102.3620\n",
      "Epoch [4/100], Loss: 101.8976\n",
      "Epoch [5/100], Loss: 101.4027\n",
      "Epoch [6/100], Loss: 100.9417\n",
      "Epoch [7/100], Loss: 100.5659\n",
      "Epoch [8/100], Loss: 100.2648\n",
      "Epoch [9/100], Loss: 100.0893\n",
      "Epoch [10/100], Loss: 99.8088\n",
      "Epoch [11/100], Loss: 100.2705\n",
      "Epoch [12/100], Loss: 101.1461\n",
      "Epoch [13/100], Loss: 101.2201\n",
      "Epoch [14/100], Loss: 100.8800\n",
      "Epoch [15/100], Loss: 101.1369\n",
      "Epoch [16/100], Loss: 100.4984\n",
      "Epoch [17/100], Loss: 100.5655\n",
      "Epoch [18/100], Loss: 100.6574\n",
      "Epoch [19/100], Loss: 100.5500\n",
      "Epoch [20/100], Loss: 100.6231\n",
      "Epoch [21/100], Loss: 100.4506\n",
      "Epoch [22/100], Loss: 100.4644\n",
      "Epoch [23/100], Loss: 100.2973\n",
      "Epoch [24/100], Loss: 100.3886\n",
      "Epoch [25/100], Loss: 100.1671\n",
      "Epoch [26/100], Loss: 100.1372\n",
      "Epoch [27/100], Loss: 100.2425\n",
      "Epoch [28/100], Loss: 100.2427\n",
      "Epoch [29/100], Loss: 100.9567\n",
      "Epoch [30/100], Loss: 100.2307\n",
      "Epoch [31/100], Loss: 100.1890\n",
      "Epoch [32/100], Loss: 100.4566\n",
      "Epoch [33/100], Loss: 100.3618\n",
      "Epoch [34/100], Loss: 100.4076\n",
      "Epoch [35/100], Loss: 100.3706\n",
      "Epoch [36/100], Loss: 100.3499\n",
      "Epoch [37/100], Loss: 100.6095\n",
      "Epoch [38/100], Loss: 100.0495\n",
      "Epoch [39/100], Loss: 100.1521\n",
      "Epoch [40/100], Loss: 100.7143\n",
      "Epoch [41/100], Loss: 100.0402\n",
      "Epoch [42/100], Loss: 100.1446\n",
      "Epoch [43/100], Loss: 100.2780\n",
      "Epoch [44/100], Loss: 100.1643\n",
      "Epoch [45/100], Loss: 100.0780\n",
      "Epoch [46/100], Loss: 100.0491\n",
      "Epoch [47/100], Loss: 100.1495\n",
      "Epoch [48/100], Loss: 100.0917\n",
      "Epoch [49/100], Loss: 100.0065\n",
      "Epoch [50/100], Loss: 100.0038\n",
      "Epoch [51/100], Loss: 100.0358\n",
      "Epoch [52/100], Loss: 99.9428\n",
      "Epoch [53/100], Loss: 99.8940\n",
      "Epoch [54/100], Loss: 99.8345\n",
      "Epoch [55/100], Loss: 99.8695\n",
      "Epoch [56/100], Loss: 99.8128\n",
      "Epoch [57/100], Loss: 99.7036\n",
      "Epoch [58/100], Loss: 99.8165\n",
      "Epoch [59/100], Loss: 99.7239\n",
      "Epoch [60/100], Loss: 99.8605\n",
      "Epoch [61/100], Loss: 99.9399\n",
      "Epoch [62/100], Loss: 100.0290\n",
      "Epoch [63/100], Loss: 99.7578\n",
      "Epoch [64/100], Loss: 99.9030\n",
      "Epoch [65/100], Loss: 99.8324\n",
      "Epoch [66/100], Loss: 99.8464\n",
      "Epoch [67/100], Loss: 99.7556\n",
      "Epoch [68/100], Loss: 99.7023\n",
      "Epoch [69/100], Loss: 99.7008\n",
      "Epoch [70/100], Loss: 99.6749\n",
      "Epoch [71/100], Loss: 99.6444\n",
      "Epoch [72/100], Loss: 99.6608\n",
      "Epoch [73/100], Loss: 99.6657\n",
      "Epoch [74/100], Loss: 99.6639\n",
      "Epoch [75/100], Loss: 99.6478\n",
      "Epoch [76/100], Loss: 99.6159\n",
      "Epoch [77/100], Loss: 99.6574\n",
      "Epoch [78/100], Loss: 99.6852\n",
      "Epoch [79/100], Loss: 99.6741\n",
      "Epoch [80/100], Loss: 99.6399\n",
      "Epoch [81/100], Loss: 99.6837\n",
      "Epoch [82/100], Loss: 99.5951\n",
      "Epoch [83/100], Loss: 99.6933\n",
      "Epoch [84/100], Loss: 99.6340\n",
      "Epoch [85/100], Loss: 99.6495\n",
      "Epoch [86/100], Loss: 99.5804\n",
      "Epoch [87/100], Loss: 99.6379\n",
      "Epoch [88/100], Loss: 99.6278\n",
      "Epoch [89/100], Loss: 99.6316\n",
      "Epoch [90/100], Loss: 99.5911\n",
      "Epoch [91/100], Loss: 99.6201\n",
      "Epoch [92/100], Loss: 99.5951\n",
      "Epoch [93/100], Loss: 99.6376\n",
      "Epoch [94/100], Loss: 99.6516\n",
      "Epoch [95/100], Loss: 99.6105\n",
      "Epoch [96/100], Loss: 99.6977\n",
      "Epoch [97/100], Loss: 99.6120\n",
      "Epoch [98/100], Loss: 99.6172\n",
      "Epoch [99/100], Loss: 99.6397\n",
      "Epoch [100/100], Loss: 99.6743\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the VAE model\n",
    "input_dim = data.shape[1]\n",
    "latent_dim = 16\n",
    "vae = VAE(input_dim, latent_dim)\n",
    "vae = vae.to(device)\n",
    "\n",
    "# Define the loss function\n",
    "reconstruction_loss = nn.MSELoss(reduction='sum')\n",
    "\n",
    "def loss_function(x, x_recon, mu, log_var):\n",
    "    bce = reconstruction_loss(x_recon, x)\n",
    "    kl_div = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    return bce + kl_div\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, len(data_tensor), batch_size):\n",
    "        batch = data_tensor[i:i+batch_size]\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x_recon, mu, log_var = vae(batch)\n",
    "        loss = loss_function(batch, x_recon, mu, log_var)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "latent_samples = torch.randn(1000, latent_dim).to(device)\n",
    "synthetic_data = vae.decode(latent_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Denormalize the synthetic data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m synthetic_data \u001b[38;5;241m=\u001b[39m \u001b[43msynthetic_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      3\u001b[0m synthetic_data \u001b[38;5;241m=\u001b[39m (synthetic_data \u001b[38;5;241m*\u001b[39m stds) \u001b[38;5;241m+\u001b[39m means\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Save the synthetic data\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "# Denormalize the synthetic data\n",
    "synthetic_data = synthetic_data.cpu().detach().numpy()\n",
    "synthetic_data = (synthetic_data * stds) + means\n",
    "\n",
    "# Save the synthetic data\n",
    "np.savetxt('synthetic_data.txt', synthetic_data, delimiter='\\t')\n",
    "\n",
    "# Visualize the synthetic data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(synthetic_data[:, 0], synthetic_data[:, 1])\n",
    "plt.xlabel('Mass')\n",
    "plt.ylabel('Intensity')\n",
    "plt.title('Synthetic Data')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Save the model\n",
    "torch.save(vae.state_dict(), 'vae_model.pth')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
