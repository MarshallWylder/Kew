{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def read_file(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            mass, intensity = line.strip().split('\\t')\n",
    "            data.append([float(mass), float(intensity)])\n",
    "    return np.array(data)\n",
    "\n",
    "directory = r'C:\\Users\\Marshall\\TEST DATA\\TEST DATA\\DalbergiaLatifolia'\n",
    "file_paths = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.txt')]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "all_data = []\n",
    "for file_path in file_paths:\n",
    "    data = pd.read_csv(file_path,sep= '\\t',header = 1)\n",
    "    all_data.append(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_scaled = []\n",
    "for seq in all_data:\n",
    "    seq = np.array(seq)\n",
    "    mass_values = seq[:, 0]\n",
    "    intensity_values = seq[:, 1]\n",
    "\n",
    "    # Calculate the minimum and maximum intensity values for this sequence\n",
    "    intensity_min = np.min(intensity_values)\n",
    "    intensity_max = np.max(intensity_values)\n",
    "\n",
    "    # Scale the intensity values using the max-min scaler\n",
    "    scaled_intensity = (intensity_values - intensity_min) / (intensity_max - intensity_min)\n",
    "\n",
    "    # Combine the scaled intensity values with the mass values\n",
    "    scaled_seq = np.column_stack((mass_values, scaled_intensity))\n",
    "\n",
    "    all_data_scaled.append(scaled_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "#all_data_scaled = np.concatenate(all_data_scaled, axis=0)\n",
    "\n",
    "max_seq_len = max(len(seq) for seq in all_data)\n",
    "\n",
    "# Create a list of tensors from the concatenated data\n",
    "tensor_data = [torch.tensor(seq, dtype=torch.float32) for seq in all_data_scaled]\n",
    "\n",
    "# Pad the sequences\n",
    "padded_data = pad_sequence(tensor_data, batch_first=True, padding_value=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = padded_data[:, :, 0].unsqueeze(-1)  # Mass values\n",
    "targets = padded_data[:, :, 1].unsqueeze(-1)   # Intensity values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask tensor for the features\n",
    "features_mask = torch.ones_like(features, dtype=torch.bool)\n",
    "for i, seq in enumerate(tensor_data):\n",
    "    features_mask[i, len(seq):, 0] = False\n",
    "\n",
    "# Create a mask tensor for the targets\n",
    "targets_mask = torch.ones_like(targets, dtype=torch.bool)\n",
    "for i, seq in enumerate(tensor_data):\n",
    "    targets_mask[i, len(seq):, 0] = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAE setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RecurrentVAE(nn.Module):\n",
    "    def __init__(self, feature_dim, target_dim, latent_dim, hidden_dim, num_layers):\n",
    "        super(RecurrentVAE, self).__init__()\n",
    "        self.feature_dim = feature_dim\n",
    "        self.target_dim = target_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder_rnn = nn.LSTM(feature_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.log_var = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder_rnn = nn.LSTM(latent_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.decoder_out = nn.Linear(hidden_dim, target_dim)\n",
    "\n",
    "    def encode(self, features, mask=None):\n",
    "        encoder_outputs, _ = self.encoder_rnn(features)\n",
    "        if mask is not None:\n",
    "            encoder_outputs = encoder_outputs * mask.unsqueeze(-1)\n",
    "        _, (h_n, _) = self.encoder_rnn(encoder_outputs)\n",
    "        h_n = h_n.view(self.num_layers, -1, self.hidden_dim)[-1]\n",
    "        mu = self.mu(h_n)\n",
    "        log_var = self.log_var(h_n)\n",
    "        return mu, log_var\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        return z\n",
    "\n",
    "    def decode(self, z, features, mask=None):\n",
    "        z = z.repeat(1, features.size(1), 1)\n",
    "        outputs, _ = self.decoder_rnn(z, (self.get_hidden_state(features, mask), None))\n",
    "        recon_targets = self.decoder_out(outputs)\n",
    "        if mask is not None:\n",
    "            recon_targets = recon_targets * mask.unsqueeze(-1)\n",
    "        return recon_targets\n",
    "\n",
    "    def get_hidden_state(self, features, mask=None):\n",
    "        encoder_outputs, _ = self.encoder_rnn(features)\n",
    "        if mask is not None:\n",
    "            encoder_outputs = encoder_outputs * mask.unsqueeze(-1)\n",
    "        _, (h_n, _) = self.encoder_rnn(encoder_outputs)\n",
    "        return h_n\n",
    "\n",
    "    def forward(self, features, targets, mask=None):\n",
    "        if mask is not None:\n",
    "            features_mask, targets_mask = mask\n",
    "        else:\n",
    "            features_mask, targets_mask = None, None\n",
    "\n",
    "        mu, log_var = self.encode(features, mask=features_mask)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        targets_recon = self.decode(z, features, mask=targets_mask)\n",
    "        return targets_recon, mu, log_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (11) must match the size of tensor b (1408) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 38\u001b[0m\n\u001b[0;32m     34\u001b[0m batch_targets_mask \u001b[38;5;241m=\u001b[39m targets_mask[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[0;32m     36\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 38\u001b[0m targets_recon, mu, log_var \u001b[38;5;241m=\u001b[39m \u001b[43mvae\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_features_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_targets_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Compute the reconstruction loss\u001b[39;00m\n\u001b[0;32m     42\u001b[0m recon_loss \u001b[38;5;241m=\u001b[39m reconstruction_loss(targets_recon \u001b[38;5;241m*\u001b[39m batch_targets_mask\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     43\u001b[0m                                  batch_targets \u001b[38;5;241m*\u001b[39m batch_targets_mask\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     44\u001b[0m                                  reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pt_gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\pt_gpu\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[71], line 59\u001b[0m, in \u001b[0;36mRecurrentVAE.forward\u001b[1;34m(self, features, targets, mask)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m     features_mask, targets_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m mu, log_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreparameterize(mu, log_var)\n\u001b[0;32m     61\u001b[0m targets_recon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode(z, features, mask\u001b[38;5;241m=\u001b[39mtargets_mask)\n",
      "Cell \u001b[1;32mIn[71], line 25\u001b[0m, in \u001b[0;36mRecurrentVAE.encode\u001b[1;34m(self, features, mask)\u001b[0m\n\u001b[0;32m     23\u001b[0m encoder_outputs, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_rnn(features)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mencoder_outputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m _, (h_n, _) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_rnn(encoder_outputs)\n\u001b[0;32m     27\u001b[0m h_n \u001b[38;5;241m=\u001b[39m h_n\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (11) must match the size of tensor b (1408) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Instantiate the model\n",
    "vae = RecurrentVAE(feature_dim=1, target_dim=1, latent_dim=32, hidden_dim=64, num_layers=2)\n",
    "\n",
    "# Move the model to GPU (if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vae = vae.to(device)\n",
    "\n",
    "# Move the data to GPU (if available)\n",
    "features = features.to(device)\n",
    "targets = targets.to(device)\n",
    "features_mask = features_mask.to(device)\n",
    "targets_mask = targets_mask.to(device)\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=0.001)\n",
    "reconstruction_loss = F.mse_loss\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "batch_size = 11\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    vae.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    for i in range(0, len(features), batch_size):\n",
    "        batch_features = features[i:i+batch_size]\n",
    "        batch_targets = targets[i:i+batch_size]\n",
    "        batch_features_mask = features_mask[i:i+batch_size]\n",
    "        batch_targets_mask = targets_mask[i:i+batch_size]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        targets_recon, mu, log_var = vae(batch_features, batch_targets,\n",
    "                                         mask=(batch_features_mask, batch_targets_mask))\n",
    "\n",
    "        # Compute the reconstruction loss\n",
    "        recon_loss = reconstruction_loss(targets_recon * batch_targets_mask.unsqueeze(-1),\n",
    "                                         batch_targets * batch_targets_mask.unsqueeze(-1),\n",
    "                                         reduction='sum')\n",
    "\n",
    "        # Compute the KL divergence loss\n",
    "        kl_div = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "\n",
    "        loss = recon_loss + kl_div\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "latent_samples = torch.randn(1000, latent_dim).to(device)\n",
    "synthetic_data = vae.decode(latent_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Denormalize the synthetic data\n",
    "synthetic_data = synthetic_data.cpu().detach().numpy()\n",
    "denormalized_samples = (synthetic_data * stds) + means\n",
    "\n",
    "# Save the synthetic data\n",
    "np.savetxt('synthetic_data.txt', denormalized_samples, delimiter='\\t')\n",
    "\n",
    "# Visualize the synthetic data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(denormalized_samples[:, 0], denormalized_samples[:, 1])\n",
    "plt.xlabel('Mass')\n",
    "plt.ylabel('Intensity')\n",
    "plt.title('Synthetic Data')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Save the model\n",
    "torch.save(vae.state_dict(), 'vae_model.pth')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
